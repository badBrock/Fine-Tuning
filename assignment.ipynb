{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:33:44.379947Z","iopub.execute_input":"2025-05-12T15:33:44.380209Z","iopub.status.idle":"2025-05-12T15:33:45.135592Z","shell.execute_reply.started":"2025-05-12T15:33:44.380191Z","shell.execute_reply":"2025-05-12T15:33:45.134816Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:33:52.851154Z","iopub.execute_input":"2025-05-12T15:33:52.851658Z","iopub.status.idle":"2025-05-12T15:34:19.340350Z","shell.execute_reply.started":"2025-05-12T15:33:52.851637Z","shell.execute_reply":"2025-05-12T15:34:19.339829Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:34:45.185659Z","iopub.execute_input":"2025-05-12T15:34:45.185923Z","iopub.status.idle":"2025-05-12T15:34:45.209585Z","shell.execute_reply.started":"2025-05-12T15:34:45.185904Z","shell.execute_reply":"2025-05-12T15:34:45.209073Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                         id  \\\n0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n2  00027e965c8264c35cc1bc55556db388da82b07f   \n3  0002c17436637c4fe1837c935c04de47adb18e9a   \n4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n\n                                             article  \\\n0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n1  (CNN) -- Ralph Mata was an internal affairs li...   \n2  A drunk driver who killed a young woman in a h...   \n3  (CNN) -- With a breezy sweep of his pen Presid...   \n4  Fleetwood are the only team still to have a 10...   \n\n                                          highlights  \n0  Bishop John Folda, of North Dakota, is taking ...  \n1  Criminal complaint: Cop used his role to help ...  \n2  Craig Eccleston-Todd, 27, had drunk at least t...  \n3  Nina dos Santos says Europe must be ready to a...  \n4  Fleetwood top of League One after 2-0 win at S...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>article</th>\n      <th>highlights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n      <td>Criminal complaint: Cop used his role to help ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n      <td>A drunk driver who killed a young woman in a h...</td>\n      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n      <td>Nina dos Santos says Europe must be ready to a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n      <td>Fleetwood are the only team still to have a 10...</td>\n      <td>Fleetwood top of League One after 2-0 win at S...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_df.drop(\"id\" , axis = 1 ,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:34:53.815493Z","iopub.execute_input":"2025-05-12T15:34:53.815758Z","iopub.status.idle":"2025-05-12T15:34:53.845378Z","shell.execute_reply.started":"2025-05-12T15:34:53.815739Z","shell.execute_reply":"2025-05-12T15:34:53.844842Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:04.854478Z","iopub.execute_input":"2025-05-12T15:35:04.854769Z","iopub.status.idle":"2025-05-12T15:35:04.965635Z","shell.execute_reply.started":"2025-05-12T15:35:04.854747Z","shell.execute_reply":"2025-05-12T15:35:04.964754Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 287113 entries, 0 to 287112\nData columns (total 2 columns):\n #   Column      Non-Null Count   Dtype \n---  ------      --------------   ----- \n 0   article     287113 non-null  object\n 1   highlights  287113 non-null  object\ndtypes: object(2)\nmemory usage: 4.4+ MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_df.iloc[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:11.542025Z","iopub.execute_input":"2025-05-12T15:35:11.542659Z","iopub.status.idle":"2025-05-12T15:35:11.548825Z","shell.execute_reply.started":"2025-05-12T15:35:11.542636Z","shell.execute_reply":"2025-05-12T15:35:11.547951Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"article       By . Associated Press . PUBLISHED: . 14:11 EST...\nhighlights    Bishop John Folda, of North Dakota, is taking ...\nName: 0, dtype: object"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_df.iloc[0]['article']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:18.141140Z","iopub.execute_input":"2025-05-12T15:35:18.141693Z","iopub.status.idle":"2025-05-12T15:35:18.146901Z","shell.execute_reply.started":"2025-05-12T15:35:18.141670Z","shell.execute_reply":"2025-05-12T15:35:18.146353Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"\"By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\""},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"script = train_df.iloc[0]['article']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:25.186294Z","iopub.execute_input":"2025-05-12T15:35:25.186560Z","iopub.status.idle":"2025-05-12T15:35:25.190434Z","shell.execute_reply.started":"2025-05-12T15:35:25.186538Z","shell.execute_reply":"2025-05-12T15:35:25.189754Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_df.iloc[0]['highlights']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:30.755947Z","iopub.execute_input":"2025-05-12T15:35:30.756228Z","iopub.status.idle":"2025-05-12T15:35:30.761531Z","shell.execute_reply.started":"2025-05-12T15:35:30.756206Z","shell.execute_reply":"2025-05-12T15:35:30.760908Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"summary = train_df.iloc[0]['highlights']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:36.156726Z","iopub.execute_input":"2025-05-12T15:35:36.156996Z","iopub.status.idle":"2025-05-12T15:35:36.160678Z","shell.execute_reply.started":"2025-05-12T15:35:36.156977Z","shell.execute_reply":"2025-05-12T15:35:36.160057Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:43.481678Z","iopub.execute_input":"2025-05-12T15:35:43.482343Z","iopub.status.idle":"2025-05-12T15:35:43.486361Z","shell.execute_reply.started":"2025-05-12T15:35:43.482317Z","shell.execute_reply":"2025-05-12T15:35:43.485828Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:49.627297Z","iopub.execute_input":"2025-05-12T15:35:49.627555Z","iopub.status.idle":"2025-05-12T15:35:50.068087Z","shell.execute_reply.started":"2025-05-12T15:35:49.627537Z","shell.execute_reply":"2025-05-12T15:35:50.067285Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"909ba2cdcb4f46ceb8f8021c08be550b"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:35:59.845543Z","iopub.execute_input":"2025-05-12T15:35:59.846347Z","iopub.status.idle":"2025-05-12T15:35:59.850700Z","shell.execute_reply.started":"2025-05-12T15:35:59.846318Z","shell.execute_reply":"2025-05-12T15:35:59.850149Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Index(['article', 'highlights'], dtype='object')"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install torch==2.5.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n!pip install \"unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:36:08.002560Z","iopub.execute_input":"2025-05-12T15:36:08.002842Z","iopub.status.idle":"2025-05-12T15:38:43.599761Z","shell.execute_reply.started":"2025-05-12T15:36:08.002822Z","shell.execute_reply":"2025-05-12T15:38:43.599057Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1.1\nLooking in indexes: https://download.pytorch.org/whl/cu124\nCollecting torch==2.5.0\n  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision\n  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\nCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio, torchvision\n\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93/10\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━\u001b[0m \u001b[32m 0/10\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.90━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.90:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.90━━━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.83━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.83:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/10\u001b[0m [nvidia-curand-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.4.1━━\u001b[0m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.8.93[0m \u001b[32m 3/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cudnn-cu120m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75━━━\u001b[0m \u001b[32m 4/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1290m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.3.90[0m \u001b[32m 5/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.3.90:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cusolver-cu12]\n\u001b[2K  Attempting uninstall: torch━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cusolver-cu12]\n\u001b[2K    Found existing installation: torch 2.5.1+cu124━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [nvidia-cusolver-cu12]\n\u001b[2K    Uninstalling torch-2.5.1+cu124:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [torch]olver-cu12]\n\u001b[2K      Successfully uninstalled torch-2.5.1+cu1240m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [torch]\n\u001b[2K  Attempting uninstall: torchaudio━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [torch]\n\u001b[2K    Found existing installation: torchaudio 2.5.1+cu124━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [torch]\n\u001b[2K    Uninstalling torchaudio-2.5.1+cu124:m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [torch]\n\u001b[2K      Successfully uninstalled torchaudio-2.5.1+cu124m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 8/10\u001b[0m [torchaudio]\n\u001b[2K  Attempting uninstall: torchvision━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 8/10\u001b[0m [torchaudio]\n\u001b[2K    Found existing installation: torchvision 0.20.1+cu124━━━━━\u001b[0m \u001b[32m 8/10\u001b[0m [torchaudio]\n\u001b[2K    Uninstalling torchvision-0.20.1+cu124:90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m 8/10\u001b[0m [torchaudio]\n\u001b[2K      Successfully uninstalled torchvision-0.20.1+cu124[0m\u001b[90m━━━\u001b[0m \u001b[32m 9/10\u001b[0m [torchvision]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [torchvision]\u001b[0m [torchvision]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.0+cu124 torchaudio-2.5.0+cu124 torchvision-0.20.0+cu124\nCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-j7jhtt7f/unsloth_4eb5f0c9d75243bf8729658a81da20dc\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-j7jhtt7f/unsloth_4eb5f0c9d75243bf8729658a81da20dc\n  Resolved https://github.com/unslothai/unsloth.git to commit c281a787b20e1dd564ee10755f9aaa86191b3e0e\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting bitsandbytes>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.5.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2022.1.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\nCollecting xformers@ https://download.pytorch.org/whl/cu124/xformers-0.0.28.post2-cp311-cp311-manylinux_2_28_x86_64.whl (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading https://download.pytorch.org/whl/cu124/xformers-0.0.28.post2-cp311-cp311-manylinux_2_28_x86_64.whl (20.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.5.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading unsloth_zoo-2025.5.1-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (24.2)\nCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.9.20-py3-none-any.whl.metadata (10 kB)\nCollecting transformers!=4.47.0,==4.51.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.30.2)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.5.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (14.0.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nCollecting fsspec (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.11.16)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.19.0)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.1.31)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (11.1.0)\nCollecting msgspec (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu124-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m141.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\nDownloading unsloth_zoo-2025.5.1-py3-none-any.whl (132 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\nDownloading tyro-0.9.20-py3-none-any.whl (125 kB)\nDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.5.1-py3-none-any.whl size=264141 sha256=ff58d92ceebe75868fe090be4ea5863b62508f7916df08ae20646a761adf1bc4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-u_7s76ak/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\nSuccessfully built unsloth\nInstalling collected packages: unsloth, shtab, msgspec, fsspec, tyro, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, bitsandbytes\n\u001b[2K  Attempting uninstall: fsspec━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/11\u001b[0m [unsloth]\n\u001b[2K    Found existing installation: fsspec 2025.3.2 \u001b[32m 0/11\u001b[0m [unsloth]\n\u001b[2K    Uninstalling fsspec-2025.3.2:━━━━━━━━━━━\u001b[0m \u001b[32m 0/11\u001b[0m [unsloth]\n\u001b[2K      Successfully uninstalled fsspec-2025.3.20m \u001b[32m 0/11\u001b[0m [unsloth]\n\u001b[2K  Attempting uninstall: transformers\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/11\u001b[0m [tyro]c]\n\u001b[2K    Found existing installation: transformers 4.51.1━━━━━━━━━━\u001b[0m \u001b[32m 4/11\u001b[0m [tyro]\n\u001b[2K    Uninstalling transformers-4.51.1:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/11\u001b[0m [transformers]\n\u001b[2K      Successfully uninstalled transformers-4.51.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/11\u001b[0m [transformers]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [bitsandbytes][0m [bitsandbytes]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 fsspec-2024.12.0 msgspec-0.19.0 shtab-1.7.2 transformers-4.51.3 trl-0.15.2 tyro-0.9.20 unsloth-2025.5.1 unsloth_zoo-2025.5.1 xformers-0.0.28.post2\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:38:59.928335Z","iopub.execute_input":"2025-05-12T15:38:59.928665Z","iopub.status.idle":"2025-05-12T15:40:08.457254Z","shell.execute_reply.started":"2025-05-12T15:38:59.928639Z","shell.execute_reply":"2025-05-12T15:40:08.456634Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Patching Xformers to fix some performance issues.\n🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-05-12 15:39:09.164276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747064349.424440      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747064349.494573      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.5.1: Fast Llama patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce6998342dd435592d18ee371a03c6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe261ea9b87a42dab0be84b37cc5aa75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54738100799146689457dbbc25ba2d90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb739acf210742a2ba18a1667789f7d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e819c1685aa4bf29ef91da887fa196f"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def find_target_modules(model, target_class_name=\"Linear4bit\", return_full_names=False):\n    \"\"\"\n    Find all unique module names in the model that match a given class name substring.\n\n    Args:\n        model (torch.nn.Module): The model to inspect.\n        target_class_name (str): Substring to look for in module types (e.g., \"Linear4bit\").\n        return_full_names (bool): If True, return full module names; otherwise, just the last part.\n\n    Returns:\n        List[str]: Unique module name parts where the target class was found.\n    \"\"\"\n    unique_layers = set()\n\n    for name, module in model.named_modules():\n        if target_class_name in type(module).__name__:\n            layer_name = name if return_full_names else name.split('.')[-1]\n            unique_layers.add(layer_name)\n\n    return sorted(unique_layers)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:40:40.618397Z","iopub.execute_input":"2025-05-12T15:40:40.618918Z","iopub.status.idle":"2025-05-12T15:40:40.623337Z","shell.execute_reply.started":"2025-05-12T15:40:40.618894Z","shell.execute_reply":"2025-05-12T15:40:40.622617Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"res = find_target_modules(model, target_class_name=\"Linear4bit\", return_full_names=False)\nprint(res)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:40:44.938681Z","iopub.execute_input":"2025-05-12T15:40:44.939629Z","iopub.status.idle":"2025-05-12T15:40:44.946075Z","shell.execute_reply.started":"2025-05-12T15:40:44.939600Z","shell.execute_reply":"2025-05-12T15:40:44.945083Z"}},"outputs":[{"name":"stdout","text":"['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 8, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = res,\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None # And LoftQ\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:40:47.739835Z","iopub.execute_input":"2025-05-12T15:40:47.740527Z","iopub.status.idle":"2025-05-12T15:40:53.687762Z","shell.execute_reply.started":"2025-05-12T15:40:47.740500Z","shell.execute_reply":"2025-05-12T15:40:53.686997Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.5.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"subset_df = train_df.sample(n=5000, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:40:57.162600Z","iopub.execute_input":"2025-05-12T15:40:57.162977Z","iopub.status.idle":"2025-05-12T15:40:57.193776Z","shell.execute_reply.started":"2025-05-12T15:40:57.162952Z","shell.execute_reply":"2025-05-12T15:40:57.193293Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"subset_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:40:58.683747Z","iopub.execute_input":"2025-05-12T15:40:58.684330Z","iopub.status.idle":"2025-05-12T15:40:58.694064Z","shell.execute_reply.started":"2025-05-12T15:40:58.684305Z","shell.execute_reply":"2025-05-12T15:40:58.693248Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                article  \\\n0     By . Mia De Graaf . Britons flocked to beaches...   \n1     A couple who weighed a combined 32st were sham...   \n2     Video footage shows the heart stopping moment ...   \n3     Istanbul, Turkey (CNN) -- About 250 people rac...   \n4     By . Daily Mail Reporter . PUBLISHED: . 12:53 ...   \n...                                                 ...   \n4995  By . Matt Chorley, Mailonline Political Editor...   \n4996  ST. POELTEN, Austria (CNN)  -- A verdict in th...   \n4997  By . Hugo Gye . PUBLISHED: . 07:49 EST, 22 Jan...   \n4998  (CNN) -- It's no Super Bowl. Heck, it's no Mon...   \n4999  London (CNN) -- India has launched a rocket it...   \n\n                                             highlights  \n0     People enjoyed temperatures of 17C at Brighton...  \n1     Couple started piling on pounds after the birt...  \n2     A 17-year-old boy suffering lacerations to his...  \n3     Syrians citizens hightail it to Turkey .\\nMost...  \n4     The Xue Long had provided the helicopter that ...  \n...                                                 ...  \n4995  Major General Jonathan Shaw accuses ministers ...  \n4996  Friztl pleads guilty to imprisonment, incest d...  \n4997  Ex-footballer, 43, has repeatedly been targete...  \n4998  ESPN moves English club soccer game to flagshi...  \n4999  Only NASA, the former Soviet Union and Europea...  \n\n[5000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>highlights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>By . Mia De Graaf . Britons flocked to beaches...</td>\n      <td>People enjoyed temperatures of 17C at Brighton...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A couple who weighed a combined 32st were sham...</td>\n      <td>Couple started piling on pounds after the birt...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Video footage shows the heart stopping moment ...</td>\n      <td>A 17-year-old boy suffering lacerations to his...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Istanbul, Turkey (CNN) -- About 250 people rac...</td>\n      <td>Syrians citizens hightail it to Turkey .\\nMost...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>By . Daily Mail Reporter . PUBLISHED: . 12:53 ...</td>\n      <td>The Xue Long had provided the helicopter that ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>By . Matt Chorley, Mailonline Political Editor...</td>\n      <td>Major General Jonathan Shaw accuses ministers ...</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>ST. POELTEN, Austria (CNN)  -- A verdict in th...</td>\n      <td>Friztl pleads guilty to imprisonment, incest d...</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>By . Hugo Gye . PUBLISHED: . 07:49 EST, 22 Jan...</td>\n      <td>Ex-footballer, 43, has repeatedly been targete...</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>(CNN) -- It's no Super Bowl. Heck, it's no Mon...</td>\n      <td>ESPN moves English club soccer game to flagshi...</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>London (CNN) -- India has launched a rocket it...</td>\n      <td>Only NASA, the former Soviet Union and Europea...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from datasets import Dataset\n\n# 1. Define the Alpaca-style prompt template\nalpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nSummarize the following text:\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\n# 2. Get the EOS token from your tokenizer\nEOS_TOKEN = tokenizer.eos_token\n\n# 3. Define the formatting function\ndef formatting_prompts_func(examples):\n    inputs = examples[\"article\"]     # raw input text\n    outputs = examples[\"highlights\"] # summary (fixed typo)\n    texts = [alpaca_prompt.format(inp, out) + EOS_TOKEN for inp, out in zip(inputs, outputs)]\n    return { \"text\": texts }\n\n# 4. Convert your DataFrame to a Hugging Face Dataset\ndataset = Dataset.from_pandas(subset_df)\n\n# 5. Apply the formatting function\ndataset = dataset.map(formatting_prompts_func, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:41:03.431129Z","iopub.execute_input":"2025-05-12T15:41:03.431376Z","iopub.status.idle":"2025-05-12T15:41:03.886545Z","shell.execute_reply.started":"2025-05-12T15:41:03.431359Z","shell.execute_reply":"2025-05-12T15:41:03.885834Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"828a7c0f7f6e42ae87586256fb656be0"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:41:06.515371Z","iopub.execute_input":"2025-05-12T15:41:06.515664Z","iopub.status.idle":"2025-05-12T15:41:06.520831Z","shell.execute_reply.started":"2025-05-12T15:41:06.515642Z","shell.execute_reply":"2025-05-12T15:41:06.520100Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['article', 'highlights', 'text'],\n    num_rows: 5000\n})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load tokenizer for Unsloth's Meta-Llama-3.1-8B model\ntokenizer = AutoTokenizer.from_pretrained(\"unsloth/Meta-Llama-3.1-8B\", use_fast=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:41:08.695234Z","iopub.execute_input":"2025-05-12T15:41:08.696082Z","iopub.status.idle":"2025-05-12T15:41:09.966611Z","shell.execute_reply.started":"2025-05-12T15:41:08.696054Z","shell.execute_reply":"2025-05-12T15:41:09.965837Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda8e39e11d84da782d8bd69c8daadc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c96e2b85789843ae8b934a26b9e19806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6eaeb40a5d46ae8e8c4a403710bb74"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = True,  # Speeds up training for short text inputs\n    args = TrainingArguments(\n        per_device_train_batch_size = 4,       # Increased for speed\n        gradient_accumulation_steps = 1,       # Simpler, higher throughput\n        num_train_epochs = 1,                  # Faster experimentation\n        warmup_steps = 10,\n        learning_rate = 5e-5,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 5,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\"\n    ),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:41:13.724661Z","iopub.execute_input":"2025-05-12T15:41:13.725507Z","iopub.status.idle":"2025-05-12T15:41:24.384802Z","shell.execute_reply.started":"2025-05-12T15:41:13.725471Z","shell.execute_reply":"2025-05-12T15:41:24.384046Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c4b0ecf771d4d64a64b6eb0d363a6e9"}},"metadata":{}},{"name":"stdout","text":"Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"gpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:41:34.550380Z","iopub.execute_input":"2025-05-12T15:41:34.550720Z","iopub.status.idle":"2025-05-12T15:41:34.556942Z","shell.execute_reply.started":"2025-05-12T15:41:34.550692Z","shell.execute_reply":"2025-05-12T15:41:34.556306Z"}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n7.137 GB of memory reserved.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:41:36.803390Z","iopub.execute_input":"2025-05-12T15:41:36.804001Z","iopub.status.idle":"2025-05-12T21:44:58.652735Z","shell.execute_reply.started":"2025-05-12T15:41:36.803966Z","shell.execute_reply":"2025-05-12T21:44:58.652093Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 5,000 | Num Epochs = 1 | Total steps = 625\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n \"-____-\"     Trainable parameters = 20,971,520/8,000,000,000 (0.26% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [625/625 6:02:46, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>2.253500</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.283700</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.129600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.131800</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>2.108400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.086900</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>1.969200</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.940800</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>2.029500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.019900</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.966100</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.003400</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.944000</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.929300</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>2.028800</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.975000</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>1.963300</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.984900</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>1.937500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.044200</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>1.911100</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.978000</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>1.962900</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.983000</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.905200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.951200</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>1.968100</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.903200</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>1.926700</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.954400</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>1.987300</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.026700</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>1.871600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.934100</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>1.854800</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.913700</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>1.936900</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>2.009700</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>1.925900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.926000</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>1.969200</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.991000</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>2.006100</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.936600</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>1.942800</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.994600</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>1.885900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.945000</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>1.966700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>2.015500</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>1.996500</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.988600</td>\n    </tr>\n    <tr>\n      <td>265</td>\n      <td>1.892800</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.932300</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>2.000500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>2.024800</td>\n    </tr>\n    <tr>\n      <td>285</td>\n      <td>1.942500</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.881900</td>\n    </tr>\n    <tr>\n      <td>295</td>\n      <td>1.935600</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.889000</td>\n    </tr>\n    <tr>\n      <td>305</td>\n      <td>2.033000</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.975900</td>\n    </tr>\n    <tr>\n      <td>315</td>\n      <td>2.000100</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.931300</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>1.956000</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.864600</td>\n    </tr>\n    <tr>\n      <td>335</td>\n      <td>1.931400</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.943200</td>\n    </tr>\n    <tr>\n      <td>345</td>\n      <td>1.946300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.888500</td>\n    </tr>\n    <tr>\n      <td>355</td>\n      <td>2.013100</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.984000</td>\n    </tr>\n    <tr>\n      <td>365</td>\n      <td>1.913300</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.929400</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>1.928500</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.928100</td>\n    </tr>\n    <tr>\n      <td>385</td>\n      <td>1.915200</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>1.877700</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>2.007900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.909100</td>\n    </tr>\n    <tr>\n      <td>405</td>\n      <td>2.010400</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>1.851900</td>\n    </tr>\n    <tr>\n      <td>415</td>\n      <td>1.943100</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>1.923100</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>1.838600</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>2.014200</td>\n    </tr>\n    <tr>\n      <td>435</td>\n      <td>1.865200</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.937600</td>\n    </tr>\n    <tr>\n      <td>445</td>\n      <td>1.931500</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.914000</td>\n    </tr>\n    <tr>\n      <td>455</td>\n      <td>1.910600</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>1.957300</td>\n    </tr>\n    <tr>\n      <td>465</td>\n      <td>1.976500</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>1.924300</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>1.889400</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.921300</td>\n    </tr>\n    <tr>\n      <td>485</td>\n      <td>1.934900</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>1.964700</td>\n    </tr>\n    <tr>\n      <td>495</td>\n      <td>1.980400</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.925700</td>\n    </tr>\n    <tr>\n      <td>505</td>\n      <td>1.918600</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>1.901300</td>\n    </tr>\n    <tr>\n      <td>515</td>\n      <td>1.967000</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>1.953600</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>1.888000</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>1.971800</td>\n    </tr>\n    <tr>\n      <td>535</td>\n      <td>1.931300</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>1.867400</td>\n    </tr>\n    <tr>\n      <td>545</td>\n      <td>1.934500</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.919500</td>\n    </tr>\n    <tr>\n      <td>555</td>\n      <td>1.967800</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>1.922400</td>\n    </tr>\n    <tr>\n      <td>565</td>\n      <td>1.985700</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>1.894000</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>1.867500</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>1.911600</td>\n    </tr>\n    <tr>\n      <td>585</td>\n      <td>1.907300</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>1.889200</td>\n    </tr>\n    <tr>\n      <td>595</td>\n      <td>1.802000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.916100</td>\n    </tr>\n    <tr>\n      <td>605</td>\n      <td>1.993700</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>1.887200</td>\n    </tr>\n    <tr>\n      <td>615</td>\n      <td>1.910300</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>1.965000</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>1.915000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"script_2 = train_df.iloc[10]['article']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:18.411359Z","iopub.execute_input":"2025-05-12T22:23:18.411935Z","iopub.status.idle":"2025-05-12T22:23:18.415620Z","shell.execute_reply.started":"2025-05-12T22:23:18.411912Z","shell.execute_reply":"2025-05-12T22:23:18.415084Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"script_2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:24.902071Z","iopub.execute_input":"2025-05-12T22:23:24.902747Z","iopub.status.idle":"2025-05-12T22:23:24.908729Z","shell.execute_reply.started":"2025-05-12T22:23:24.902715Z","shell.execute_reply":"2025-05-12T22:23:24.907842Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"\"By . Ellie Zolfagharifard . Take a look at a map today, and you’re likely to see that North America is larger than Africa, Alaska is larger than Mexico and China is smaller than Greenland. But in reality China is four times bigger than Greenland, Africa is three times bigger than North America and Mexico is larger than Alaska. The distortion is the result of the Mercator projection, the map most commonly seen hanging in classrooms and in text books, which was created in 1596 to help sailors navigate the world. The Mercator projection, the map most commonly seen hanging in classrooms and in text books, was created in 1596 to help sailors navigate the world. The familiar map gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north . You might think that the advent of satellite imagery and tools such as Google maps has improved our view of the world, but this isn’t necessarily the case, according to James Wan writing in the Guardian. Much of this is due to technical reasons, said Mr Wan, while others inconsistences are caused by ideological assumptions that can change the way we see the world. The biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map – a problem that has haunted cartographers for centuries. One of the best alternatives to the Mercator projection was presented in 1974 by D. Arno Peters (pictured). The Gall-Peters projection makes seeing the relative size of places much easier. However it also has its flaws as certain places appear stretched, horizontally near the poles and vertically near the Equator . A depiction of the world by Henricus Martellus. It's said that Columbus used this map or one like it to persuade Ferdinand of Aragon and Isabella of Castile to support him in the early 1490s. The map was made by a German cartographer living in Florence and reflects the latest theories about the form of the world and the most accurate ways of portraying it on a flat surface . Africa is around 14 times larger than Greenland and yet on the map both are almost same size. Brazil is more than five times larger than Alaska, yet Alaska is larger than Brazil on the map. The map suggests that Scandinavian countries are larger than India, whereas in reality India is three times the size of all Scandinavian countries put together. While it looks like Europe is larger than North America on this map, in reality the reverse is true. Russia also isn't as large as it is depicted, with Africa larger than Russia in reality. As a result, shapes of world maps have typically been diverse, ranging from hearts to cones. But the diversity gradually faded away with one model, invented by Gerardus Mercator, surpassing the others. The familiar 'Mercator' projection gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north. For instance, in the Mercator projection, north America looks at least as big, if not slightly larger, than Africa. And Greenland also looks of comparable size. But in reality Africa is larger than both. In fact, you can fit north America into Africa and still have space for India, Argentina, Tunisia and some left over, notes Mr Wan. Greenland, meanwhile, is 1/14th the size of the continent as can be seen in Gall-Peters equal projection, which provides the correct proportion of land mass to the continents. The map suggests that Scandinavian countries are larger than India, whereas in reality India is three times the size of all Scandinavian countries put together. As well, as this, it seems the fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. Looking back, the diversity of maps can reveal a history of the world. The Chinese Globe which was made for the Chinese Emperor in 1623. The creators exaggerated the size of China and placed it in the middle of a world that otherwise consisted mainly of small offshore islands . The Werner heart-shaped project of the world (left) The fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. Pictured on the right is a Mercator map turned on its head . For instance, The ‘Be On Guard!’ map was . created in 1921 when infant USSR was threatened with invasion, famine . and social unrest. To counter this, designers such as Dimitri Moor were employed to create pro-Bolshevik propaganda. Using a map of European Russia and its neighbours, Moor's image of a heroic Bolshevik guard defeating the invading 'Whites' helped define the Soviet Union in the Russian popular imagination. An earlier map, called the Hinese Globe, created in 1623 reveals the ancient Chinese view of the world. Made for the Chinese Emperor, this is the earliest known Chinese terrestrial globe, and a fusion of East and Western cultures. The creators exaggerated the size of China and placed it in the middle of a world that otherwise consisted mainly of small off¬shore islands. A century earlier, the 1507 Waldseemuller map named and envisaged America as a separate continent for the first time. Photo of a genuine hand drawn world map, it was drawn in 1844 and therefore the countries are named as they were in that period. The biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map . Perhaps to emphasise the independent existence of the Americas, the map shows what we now know is the Pacific lapping the western coast of South America, though its existence was only confirmed years late. In 2005, Google Earth presented a world in which the area of most concern to the used could be at the centre, and which - with mapped content overlaid - can contain whatever you think is important. Almost for the first time, the ability to create an accurate map has been placed in the hands of everyone, and it has transformed the way we view the world. But it comes at a price. There are few, if any, agreed standards about what should be included, and the less populated and 'less important' regions get ignored. The infant USSR was threatened with invasion, famine and social unrest. To counter this, brilliant designers such as Dimitri Moor were employed to create pro-Bolshevik propaganda. Using a map of European Russia and its neighbours, Moor's image of a heroic Bolshevik guard defeating the invading 'Whites' helped define the Soviet Union in the Russian popular imagination . Google Maps claims that it is on a 'never-ending quest for the perfect map', but Jerry Brotton, historian of cartography and the author of A History of the World in Twelve Maps, isn't so sure . A Mercator map created in 1569. In the Mercator projection, north America looks at least as big, if not slightly larger, than Africa. And Greenland also looks of comparable size . Today, billions of searches are made on Google Maps each day, helping people navigate their way around, streets, towns and countries. Google Maps claims that it is on a ‘never-ending quest for the perfect map’, but Jerry Brotton, historian of cartography and the author of A History of the World in Twelve Maps, isn’t so sure. He argues that all maps are of their time, their place and serve certain purposes. ‘No world map is, or can be, a definitive, transparent depiction of its subject that offers a disembodied eye onto the world,’ he writes. ‘Each one is a continual negotiation between its makers and users, as their understanding of the world changes.’ This map was used in 1782 by British diplomats negotiating an end to the American War of Independence in Paris. Richard Oswald, secretary to the delegation, annotated it with coloured lines to show where it was thought past treaties established the U.S./Canada border .\""},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch, re\n\n# Enable fast inference mode\nFastLanguageModel.for_inference(model)\n\n# Add special tokens to ensure proper stopping\nif tokenizer.eos_token is None:\n    tokenizer.eos_token = \"</s>\"\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Ultra-simplified prompt with explicit end markers\nprompt = f\"\"\"<|im_start|>system\nYou are a summarization AI. Generate only a 2-3 sentence summary. Always complete your sentences.\n<|im_end|>\n<|im_start|>user\nSummarize this article in 2-3 complete sentences:\n\n{script_2}\n<|im_end|>\n<|im_start|>assistant\n\"\"\"\n\n# Add explicit ending tokens to the tokenizer's vocabulary if not present\nend_token = \"<|im_end|>\"\nif end_token not in tokenizer.get_vocab():\n    print(\"End token not in vocabulary, using EOS token instead\")\n    end_token = tokenizer.eos_token\n\n# Tokenize\ninputs = tokenizer(\n    [prompt],\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True,\n    max_length=2048,\n).to(\"cuda\")\n\n# Force the model to generate a complete summary\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=200,\n    min_new_tokens=20,\n    temperature=0.1,  # Very low temperature to reduce randomness\n    top_p=0.5,       # More restrictive top_p\n    do_sample=False, # Turn off sampling for more deterministic output\n    num_beams=None,     # Use beam search for better completion\n    early_stopping=True,\n    repetition_penalty=1.0,  # Default repetition penalty\n    length_penalty=1.0,      # No length penalty\n    use_cache=True\n)\n\n# Get the generated text\nfull_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\ninput_text = tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)\nsummary = full_output[len(input_text):].strip()\n\n# Final cleanup to ensure we have only the summary\nsummary = re.sub(r'(?i)(summary:|the summary is:|here\\'s a summary:|step-by-step|instructions:|note:|###)', '', summary)\nsummary = re.sub(r'^\\d+\\.[\\s]*', '', summary, flags=re.MULTILINE)\nsummary = re.sub(r'^\\*[\\s]*', '', summary, flags=re.MULTILINE)\nsummary = re.sub(r'<\\|im_end\\|>.*', '', summary, flags=re.MULTILINE)\n\n\n\n\n, '', summary, flags=re.DOTALL)  # Remove anything after end token\n\n# Ensure the summary ends with proper punctuation\nif summary and not summary[-1] in ['.', '!', '?']:\n    # Find the last complete sentence\n    last_sentence_end = max(summary.rfind('.'), summary.rfind('!'), summary.rfind('?'))\n    if last_sentence_end > 0:\n        summary = summary[:last_sentence_end+1]\n\nprint(\"SUMMARY:\\n\", summary.strip())\n\n# Post-processing function to call if you still get incomplete summaries\ndef get_complete_sentences(text):\n    \"\"\"Extract only complete sentences from text\"\"\"\n    sentences = re.findall(r'[^.!?]*[.!?]', text)\n    if len(sentences) == 0:\n        return text  # Return original if no complete sentences found\n    return ' '.join(sentences)\n\n# Uncomment this line if you still get incomplete summaries\n# print(\"CLEANED SUMMARY:\\n\", get_complete_sentences(summary))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:54:32.619075Z","iopub.execute_input":"2025-05-12T22:54:32.619737Z","iopub.status.idle":"2025-05-12T22:54:46.818224Z","shell.execute_reply.started":"2025-05-12T22:54:32.619712Z","shell.execute_reply":"2025-05-12T22:54:46.817626Z"}},"outputs":[{"name":"stdout","text":"End token not in vocabulary, using EOS token instead\nSUMMARY:\n By. Ellie Zolfagharifard. Take a look at a map today, and you’re likely to see that North America is larger than Africa, Alaska is larger than Mexico and China is smaller than Greenland. But in reality China is four times bigger than Greenland, Africa is three times bigger than North America and Mexico is larger than Alaska. The distortion is the result of the Mercator projection, the map most commonly seen hanging in classrooms and in text books, which was created in 1596 to help sailors navigate the world. The Mercator projection, the map most commonly seen hanging in classrooms and in text books, was created in 1596 to help sailors navigate the world. The familiar map gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north.\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"high_2 = train_df.iloc[10]['highlights']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:53:57.224631Z","iopub.execute_input":"2025-05-12T22:53:57.224929Z","iopub.status.idle":"2025-05-12T22:53:57.229685Z","shell.execute_reply.started":"2025-05-12T22:53:57.224908Z","shell.execute_reply":"2025-05-12T22:53:57.228953Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"high_2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:54:02.976000Z","iopub.execute_input":"2025-05-12T22:54:02.976247Z","iopub.status.idle":"2025-05-12T22:54:02.980771Z","shell.execute_reply.started":"2025-05-12T22:54:02.976230Z","shell.execute_reply":"2025-05-12T22:54:02.980232Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"'The distortion is the result of the Mercator map which was created in 1596 to help sailors navigate the world .\\nIt gives the right shapes of countries but at the cost of distorting sizes in favour of the wealthy lands to the north .\\nFor instance, north America looks larger, or at least as big, as Africa, and Greenland also looks of comparable size .\\nIn reality, you can fit north America into Africa and still have space for India, Argentina, Tunisia and some left over .\\nMap suggests Scandinavian countries are larger than India, whereas in reality India is three times the size .\\nThe biggest challenge for cartographers is that it is impossible to portray reality of spherical world on a flat map .'"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"model.push_to_hub(\"badbrock/llama3-1b-lora-summary\")\ntokenizer.push_to_hub(\"badbrock/llama3-1b-lora-summary\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:57:57.846750Z","iopub.execute_input":"2025-05-12T22:57:57.847084Z","iopub.status.idle":"2025-05-12T22:58:03.987510Z","shell.execute_reply.started":"2025-05-12T22:57:57.847057Z","shell.execute_reply":"2025-05-12T22:58:03.986746Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/607 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9846154399024143b03ba06dab6aaf38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/83.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e512baf2a44db2ad5759bb4dbacfd6"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/badbrock/llama3-1b-lora-summary\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79d2fb9fb0304d909534f1c285961227"}},"metadata":{}},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/badbrock/llama3-1b-lora-summary/commit/295b7ecbea4cd2fe46c7b230b2951a8f9a154f53', commit_message='Upload tokenizer', commit_description='', oid='295b7ecbea4cd2fe46c7b230b2951a8f9a154f53', pr_url=None, repo_url=RepoUrl('https://huggingface.co/badbrock/llama3-1b-lora-summary', endpoint='https://huggingface.co', repo_type='model', repo_id='badbrock/llama3-1b-lora-summary'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":79}]}